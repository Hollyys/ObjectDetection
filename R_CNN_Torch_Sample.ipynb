{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1CWIHz1URWERbE4_bz1BRdsLbbHQI5N8k","timestamp":1676595675784}],"authorship_tag":"ABX9TyPPAUjiN5NRNkbuDFZSLg2d"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["jupyter-lab --allow-root --NotebookApp.allow_origin='https://colab.research.google.com' --port=8888 --NotebookApp.port_retries=0"],"metadata":{"id":"1vjHbyq9PhaV"}},{"cell_type":"code","source":["!pip install pycocotools --quiet\n","!git clone https://github.com/pytorch/vision.git\n","!git checkout v0.3.0\n","\n","!cp vision/references/detection/utils.py ./\n","!cp vision/references/detection/transforms.py ./\n","!cp vision/references/detection/coco_eval.py ./\n","!cp vision/references/detection/engine.py ./\n","!cp vision/references/detection/coco_utils.py ./"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K6Hrh2FUkJNr","executionInfo":{"status":"ok","timestamp":1689743642984,"user_tz":-540,"elapsed":78593,"user":{"displayName":"신성한","userId":"02352508022902564974"}},"outputId":"4d5987e7-1882-4c5e-a53f-980ec240620c"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\r\n","  \r\n","  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for pycocotools \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\r\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\r\n","  \u001b[31m╰─>\u001b[0m \u001b[31m[22 lines of output]\u001b[0m\r\n","  \u001b[31m   \u001b[0m running bdist_wheel\r\n","  \u001b[31m   \u001b[0m running build\r\n","  \u001b[31m   \u001b[0m running build_py\r\n","  \u001b[31m   \u001b[0m creating build\r\n","  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-311\r\n","  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-311/pycocotools\r\n","  \u001b[31m   \u001b[0m copying pycocotools/coco.py -> build/lib.macosx-10.9-x86_64-cpython-311/pycocotools\r\n","  \u001b[31m   \u001b[0m copying pycocotools/mask.py -> build/lib.macosx-10.9-x86_64-cpython-311/pycocotools\r\n","  \u001b[31m   \u001b[0m copying pycocotools/__init__.py -> build/lib.macosx-10.9-x86_64-cpython-311/pycocotools\r\n","  \u001b[31m   \u001b[0m copying pycocotools/cocoeval.py -> build/lib.macosx-10.9-x86_64-cpython-311/pycocotools\r\n","  \u001b[31m   \u001b[0m running build_ext\r\n","  \u001b[31m   \u001b[0m /private/var/folders/mp/4941wy2j1n5_72tw28nm76d40000gn/T/pip-build-env-n9zalktc/overlay/lib/python3.11/site-packages/Cython/Compiler/Main.py:381: FutureWarning: Cython directive 'language_level' not set, using '3str' for now (Py3). This has changed from earlier releases! File: /private/var/folders/mp/4941wy2j1n5_72tw28nm76d40000gn/T/pip-install-ls3x9gsg/pycocotools_589da874c2fe423abaff2d35e31e49a7/pycocotools/_mask.pyx\r\n","  \u001b[31m   \u001b[0m   tree = Parsing.p_module(s, pxd, full_module_name)\r\n","  \u001b[31m   \u001b[0m Compiling pycocotools/_mask.pyx because it changed.\r\n","  \u001b[31m   \u001b[0m [1/1] Cythonizing pycocotools/_mask.pyx\r\n","  \u001b[31m   \u001b[0m building 'pycocotools._mask' extension\r\n","  \u001b[31m   \u001b[0m creating build/temp.macosx-10.9-x86_64-cpython-311\r\n","  \u001b[31m   \u001b[0m creating build/temp.macosx-10.9-x86_64-cpython-311/common\r\n","  \u001b[31m   \u001b[0m creating build/temp.macosx-10.9-x86_64-cpython-311/pycocotools\r\n","  \u001b[31m   \u001b[0m clang -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /Users/crossrunway/anaconda3/envs/ObjectDetection/include -fPIC -O2 -isystem /Users/crossrunway/anaconda3/envs/ObjectDetection/include -I/private/var/folders/mp/4941wy2j1n5_72tw28nm76d40000gn/T/pip-build-env-n9zalktc/overlay/lib/python3.11/site-packages/numpy/core/include -I./common -I/Users/crossrunway/anaconda3/envs/ObjectDetection/include/python3.11 -c ./common/maskApi.c -o build/temp.macosx-10.9-x86_64-cpython-311/./common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\r\n","  \u001b[31m   \u001b[0m xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun\r\n","  \u001b[31m   \u001b[0m error: command '/usr/bin/clang' failed with exit code 1\r\n","  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\r\n","  \r\n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\r\n","\u001b[31m  ERROR: Failed building wheel for pycocotools\u001b[0m\u001b[31m\r\n","\u001b[0m\u001b[31mERROR: Could not build wheels for pycocotools, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n","\u001b[0m'vision'에 복제합니다...\n","remote: Enumerating objects: 348884, done.\u001b[K\n","remote: Counting objects: 100% (83983/83983), done.\u001b[K\n","remote: Compressing objects: 100% (1838/1838), done.\u001b[K\n","remote: Total 348884 (delta 82717), reused 83213 (delta 82092), pack-reused 264901\u001b[K\n","오브젝트를 받는 중: 100% (348884/348884), 704.28 MiB | 13.09 MiB/s, 완료.\n","델타를 알아내는 중: 100% (321696/321696), 완료.\n","fatal: (현재 폴더 또는 상위 폴더 중 일부가) 깃 저장소가 아닙니다: .git\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import os\n","import random\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","import cv2\n","import torch\n","import torchvision\n","from torchvision import transforms, datasets\n","from torchvision.models.detection import *\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","\n","# import pyttsx3\n","# engine = pyttsx3.init()\n","\n","from engine import train_one_epoch, evaluate\n","import utils\n","import transforms as T\n","\n","# For image augmentations\n","import albumentations as A\n","from albumentations.pytorch.transforms import ToTensorV2\n","\n","# As the data directory contains .xml files\n","from xml.etree import ElementTree as et\n","\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"YnvAis3ofkMv","executionInfo":{"status":"error","timestamp":1689746172756,"user_tz":-540,"elapsed":653,"user":{"displayName":"신성한","userId":"02352508022902564974"}},"outputId":"55c83c6d-0897-464a-c477-dc6b8ca1ad04"},"execution_count":19,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[0;32mIn[19], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mT\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# For image augmentations\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01malbumentations\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mA\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01malbumentations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ToTensorV2\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# As the data directory contains .xml files\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/ObjectDetection/lib/python3.11/site-packages/albumentations/__init__.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m absolute_import\n\u001b[1;32m      3\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.3.1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maugmentations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomposition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserialization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n","File \u001b[0;32m~/anaconda3/envs/ObjectDetection/lib/python3.11/site-packages/albumentations/augmentations/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Common classes\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mblur\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mblur\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcrops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n","File \u001b[0;32m~/anaconda3/envs/ObjectDetection/lib/python3.11/site-packages/albumentations/augmentations/blur/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n","File \u001b[0;32m~/anaconda3/envs/ObjectDetection/lib/python3.11/site-packages/albumentations/augmentations/blur/functional.py:9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01malbumentations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maugmentations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convolve\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01malbumentations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maugmentations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m scale\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01malbumentations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maugmentations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     11\u001b[0m     _maybe_process_in_chunks,\n\u001b[1;32m     12\u001b[0m     clipped,\n\u001b[1;32m     13\u001b[0m     preserve_shape,\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     16\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblur\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian_blur\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgaussian_blur\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglass_blur\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n","File \u001b[0;32m~/anaconda3/envs/ObjectDetection/lib/python3.11/site-packages/albumentations/augmentations/geometric/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrotate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n","File \u001b[0;32m~/anaconda3/envs/ObjectDetection/lib/python3.11/site-packages/albumentations/augmentations/geometric/functional.py:6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mskimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransform\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mndimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gaussian_filter\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01malbumentations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maugmentations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     10\u001b[0m     _maybe_process_in_chunks,\n\u001b[1;32m     11\u001b[0m     angle_2pi_range,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     preserve_shape,\n\u001b[1;32m     15\u001b[0m )\n","File \u001b[0;32m~/anaconda3/envs/ObjectDetection/lib/python3.11/site-packages/skimage/transform/__init__.py:38\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"This module includes tools to transform images and volumetric data.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m- Geometric transformation:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhough_transform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (hough_line, hough_line_peaks,\n\u001b[1;32m     36\u001b[0m                               probabilistic_hough_line, hough_circle,\n\u001b[1;32m     37\u001b[0m                               hough_circle_peaks, hough_ellipse)\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mradon_transform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (radon, iradon, iradon_sart,\n\u001b[1;32m     39\u001b[0m                               order_angles_golden_ratio)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfinite_radon_transform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frt2, ifrt2\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegral\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m integral_image, integrate\n","File \u001b[0;32m~/anaconda3/envs/ObjectDetection/lib/python3.11/site-packages/skimage/transform/radon_transform.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterpolate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m interp1d\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m golden_ratio\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfft\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fft, ifft, fftfreq, fftshift\n","File \u001b[0;32m~/anaconda3/envs/ObjectDetection/lib/python3.11/site-packages/scipy/interpolate/__init__.py:167\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m========================================\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mInterpolation (:mod:`scipy.interpolate`)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m(should not be used in new code).\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_interpolate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fitpack_py\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# New interface to fitpack library:\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/ObjectDetection/lib/python3.11/site-packages/scipy/interpolate/_interpolate.py:12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mspec\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m comb\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _fitpack_py\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dfitpack\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_polyint\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _Interpolator1D\n","File \u001b[0;32m~/anaconda3/envs/ObjectDetection/lib/python3.11/site-packages/scipy/interpolate/_fitpack_py.py:10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fitpack_impl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m bisplrep, bisplev, dblint  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _fitpack_impl \u001b[38;5;28;01mas\u001b[39;00m _impl\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bsplines\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BSpline\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplprep\u001b[39m(x, w\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, u\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, ub\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, ue\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, task\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, s\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, t\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     14\u001b[0m             full_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, nest\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, per\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, quiet\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     15\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m    Find the B-spline representation of an N-D curve.\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    152\u001b[0m \n\u001b[1;32m    153\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/ObjectDetection/lib/python3.11/site-packages/scipy/interpolate/_bsplines.py:9\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmultiarray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m normalize_axis_index\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (get_lapack_funcs, LinAlgError,\n\u001b[1;32m      7\u001b[0m                           cholesky_banded, cho_solve_banded,\n\u001b[1;32m      8\u001b[0m                           solve, solve_banded)\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m minimize_scalar\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _bspl\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _fitpack_impl\n","File \u001b[0;32m~/anaconda3/envs/ObjectDetection/lib/python3.11/site-packages/scipy/optimize/__init__.py:410\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m=====================================================\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mOptimization and root finding (:mod:`scipy.optimize`)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    406\u001b[0m \n\u001b[1;32m    407\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_optimize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m--> 410\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_minimize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_root\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_root_scalar\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n","File \u001b[0;32m~/anaconda3/envs/ObjectDetection/lib/python3.11/site-packages/scipy/optimize/_minimize.py:27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_trustregion_krylov\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _minimize_trust_krylov\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_trustregion_exact\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _minimize_trustregion_exact\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_trustregion_constr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _minimize_trustregion_constr\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# constrained minimization\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lbfgsb_py\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _minimize_lbfgsb\n","File \u001b[0;32m~/anaconda3/envs/ObjectDetection/lib/python3.11/site-packages/scipy/optimize/_trustregion_constr/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"This module contains the equality constrained SQP solver.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mminimize_trustregion_constr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _minimize_trustregion_constr\n\u001b[1;32m      6\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_minimize_trustregion_constr\u001b[39m\u001b[38;5;124m'\u001b[39m]\n","File \u001b[0;32m~/anaconda3/envs/ObjectDetection/lib/python3.11/site-packages/scipy/optimize/_trustregion_constr/minimize_trustregion_constr.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearOperator\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_differentiable_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VectorFunction\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_constraints\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      6\u001b[0m     NonlinearConstraint, LinearConstraint, PreparedConstraint, strict_bounds)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_hessian_update_strategy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BFGS\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_optimize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OptimizeResult\n","File \u001b[0;32m~/anaconda3/envs/ObjectDetection/lib/python3.11/site-packages/scipy/optimize/_constraints.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_optimize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OptimizeWarning\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m warn, catch_warnings, simplefilter\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m suppress_warnings\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m issparse\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_arr_to_scalar\u001b[39m(x):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# If x is a numpy array, return x.item().  This will\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# fail if the array has more than one element.\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/ObjectDetection/lib/python3.11/site-packages/numpy/testing/__init__.py:14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_private\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (_assert_valid_refcount, _gen_alignment_data)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_private\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m extbuild, decorators \u001b[38;5;28;01mas\u001b[39;00m dec\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_private\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnosetester\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     15\u001b[0m     run_module_suite, NoseTester \u001b[38;5;28;01mas\u001b[39;00m Tester\n\u001b[1;32m     16\u001b[0m     )\n\u001b[1;32m     18\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m _private\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39m__all__ \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTestCase\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun_module_suite\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pytesttester\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PytestTester\n","File \u001b[0;32m~/anaconda3/envs/ObjectDetection/lib/python3.11/site-packages/numpy/testing/_private/nosetester.py:12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m import_nose, suppress_warnings\n\u001b[1;32m     15\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mget_package_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun_module_suite\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNoseTester\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     16\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_numpy_tester\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mget_package_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimport_nose\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     17\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuppress_warnings\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_package_name\u001b[39m(filepath):\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'import_nose' from 'numpy.testing._private.utils' (/Users/crossrunway/anaconda3/envs/ObjectDetection/lib/python3.11/site-packages/numpy/testing/_private/utils.py)"]}]},{"cell_type":"code","source":["# defining the files directory and testing directory\n","files_dir = '../input/fruit-images-for-object-detection/train_zip/train'\n","test_dir = '../input/fruit-images-for-object-detection/test_zip/test'"],"metadata":{"id":"VA7Qv_AUf6qQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class FruitImageDataset(torch.utils.data.Dataset):\n","\n","    def __init__(self, files_dir, width, height, transforms=None):\n","        self.files_dir = files_dir\n","        self.width = width\n","        self.height = height\n","        self.transforms = transforms  # If transformation is required, when transforms is not None\n","\n","        self.classes_ = [_, 'apple', 'orange', 'banana']  # Defining classes, a blank class is given for the background\n","\n","        self.images = [img for img in sorted(os.listdir(files_dir)) if img[-4:]=='.jpg']\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        img_name = self.images[idx]\n","        img_path = os.path.join(self.files_dir, img_name)\n","\n","        # Reading the image\n","        img = cv2.imread(img_path)\n","\n","        # Defining width and height\n","        wt = img.shape[1]\n","        ht = img.shape[0]\n","\n","        # Converting image to RGB channel and normalizing the image\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n","        img = cv2.resize(img, (self.width, self.height), cv2.INTER_AREA)\n","        img /= 255.0\n","\n","        annot_name = img_name[:-4] + '.xml'\n","        annot_path = os.path.join(self.files_dir, annot_name)\n","\n","        # Boxes to store the coordinate points of the bboxes\n","        boxes, labels = [], []\n","\n","        tree = et.parse(annot_path)\n","        root = tree.getroot()\n","\n","        # Box coordinates are extracted from the XML files for the given image size\n","        for member in root.findall('object'):\n","            labels.append(self.classes_.index(member.find('name').text))\n","\n","            xmin = float(member.find('bndbox').find('xmin').text)\n","            xmax = float(member.find('bndbox').find('xmax').text)\n","            ymin = float(member.find('bndbox').find('ymin').text)\n","            ymax = float(member.find('bndbox').find('ymax').text)\n","\n","            x_min = (xmin/wt)*self.width\n","            x_max = (xmax/wt)*self.width\n","            y_min = (ymin/ht)*self.height\n","            y_max = (ymax/ht)*self.height\n","\n","            boxes.append([x_min, y_min, x_max, y_max])\n","\n","        # Conversion to Tensors\n","        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n","        area = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])  # Calculating area of the boxes\n","\n","        iscrowd = torch.zeros((boxes.shape[0], ), dtype=torch.int64)\n","\n","        labels = torch.as_tensor(labels, dtype=torch.int64)\n","\n","        image_id = torch.tensor([idx])\n","\n","        target = {'boxes': boxes, 'area': area, 'labels': labels,\n","                'iscrowd': iscrowd, 'image_id':image_id}\n","\n","        if self.transforms:\n","            sample = self.transforms(image = img,\n","                                    bboxes = target['boxes'],\n","                                    labels = labels)\n","\n","            img = sample['image']\n","            target['boxes'] = torch.Tensor(sample['bboxes'])\n","\n","        return img, target"],"metadata":{"id":"vufffBCdf-MC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Observing the dataset without any transformation\n","dataset = FruitImageDataset(files_dir, 224, 224)\n","print('length of dataset = ', len(dataset), '\\n')"],"metadata":{"id":"JhgKGu3wgBzT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img, target = dataset[78]\n","print(img.shape, '\\n',target)"],"metadata":{"id":"HMiu40HfgEaw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_img_bbox(img, target):\n","\n","    # plot the image and bboxes\n","    # Bounding boxes are defined as follows: x-min y-min width height\n","    fig, a = plt.subplots(1,1)\n","    fig.set_size_inches(5,5)\n","    a.imshow(img)\n","\n","    for box in (target['boxes']):\n","        x, y, width, height  = box[0], box[1], box[2]-box[0], box[3]-box[1]\n","        rect = patches.Rectangle((x, y),\n","                                 width, height,\n","                                 linewidth = 2,\n","                                 edgecolor = 'r',\n","                                 facecolor = 'none')\n","\n","        # Draw the bounding box on top of the image\n","        a.add_patch(rect)\n","    plt.show()"],"metadata":{"id":"mTSBLfKfgG-y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img, target = dataset[25]\n","plot_img_bbox(img, target)"],"metadata":{"id":"_hfsOt8IgJFt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img, target = dataset[78]\n","plot_img_bbox(img, target)"],"metadata":{"id":"treS5ZA9gK-y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_model(num_classes, modelName):\n","\n","    # Loading the pre-trained model\n","    if modelName == 'fastcnn':\n","        model = fasterrcnn_resnet50_fpn(pretrained=True)\n","        in_features = model.roi_heads.box_predictor.cls_score.in_features\n","        model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n","        return model\n","\n","    elif modelName == 'maskcnn':\n","        model = maskrcnn_resnet50_fpn(pretrained=True)\n","        in_features = model.roi_heads.box_predictor.cls_score.in_features\n","        model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n","        return model"],"metadata":{"id":"7fdnhNcagNlM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_transform(train=True):\n","    if train:\n","        return A.Compose([\n","            A.HorizontalFlip(0.5),\n","            ToTensorV2(p=0.1),     # ToTensorV2 converts image to PyTorch tensor without dividing by 255\n","        ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels']))\n","    else:\n","        return A.Compose([\n","            ToTensorV2(p=0.1),     # ToTensorV2 converts image to PyTorch tensor without dividing by 255\n","        ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels']))"],"metadata":{"id":"vhHc9Z3mgQy8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_split = 0.2\n","\n","# Loading the training and the testing data with all tghe transformations\n","dataset_train = FruitImageDataset(files_dir, 480, 480, transforms=get_transform(train=True))\n","dataset_test = FruitImageDataset(files_dir, 480, 480, transforms=get_transform(train=False))\n","\n","torch.manual_seed(1)\n","indices = torch.randperm(len(dataset)).tolist()\n","\n","# Train test split\n","tsize = int(len(dataset) * test_split) # Getting the splitting index\n","dataset_train = torch.utils.data.Subset(dataset_train, indices[:-tsize])\n","dataset_test = torch.utils.data.Subset(dataset_test, indices[-tsize:])\n","\n","# Defining dataloaders\n","dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=8, shuffle=True,\n","                                              num_workers=4, collate_fn=utils.collate_fn)  # Imported form helper library\n","dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=8, shuffle=True,\n","                                              num_workers=4, collate_fn=utils.collate_fn)"],"metadata":{"id":"pfuxj6HwgT4V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","\n","num_classes = 4 # Can try by changing to 3 as 1 class is devoted for background\n","num_epochs = 9\n","\n","def start_training(modelName, num_epochs, num_classes):\n","    model = get_model(num_classes, modelName)\n","    model.to(device)\n","    params = [p for p in model.parameters() if p.requires_grad]\n","    optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.005)\n","\n","    # Learning rate decreases by 10 every 5 epochs\n","    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n","\n","    for epoch in range(num_epochs):\n","        train_one_epoch(model, optimizer, dataloader_train, device, epoch, print_freq=5)\n","        lr_scheduler.step()\n","        evaluate(model, dataloader_test, device=device)\n","    return model"],"metadata":{"id":"tpOXpaGZgWJI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fast_rcnn = start_training('fastcnn', num_epochs, num_classes)"],"metadata":{"id":"Y6KS8Mo1gYTr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def apply_nms(prediction, threshold):\n","    # torchvision returns the indices of the boxes to keep\n","    keep = torchvision.ops.nms(prediction['boxes'], prediction['scores'], threshold)\n","\n","    final_prediction = prediction\n","    final_prediction['boxes'] = final_prediction['boxes'][keep]\n","    final_prediction['scores'] = final_prediction['scores'][keep]\n","    final_prediction['labels'] = final_prediction['labels'][keep]\n","\n","    return final_prediction\n","\n","# Function to convert a torch tensor to a PIL Image\n","def tensorToPIL(img):\n","    return transforms.ToPILImage()(img).convert('RGB')"],"metadata":{"id":"UZd8u9HigbMl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# pick one image from the test set\n","img, target = dataset_test[5]\n","\n","# put the model in evaluation mode\n","fast_rcnn.eval()\n","with torch.no_grad():\n","    prediction = fast_rcnn([img.to(device)])[0]\n","\n","print('predicted #boxes: ', len(prediction['labels']))\n","print('real #boxes: ', len(target['labels']))"],"metadata":{"id":"cOU7soNgged8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('EXPECTED OUTPUT')\n","plot_img_bbox(tensorToPIL(img), target)"],"metadata":{"id":"Biy0svmvgg6d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('MODEL OUTPUT')\n","plot_img_bbox(tensorToPIL(img), prediction)"],"metadata":{"id":"j_PyVlvZgi5k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nms_preds = apply_nms(prediction, threshold=0.2)\n","print('NMS APPLIED MODEL OUTPUT')\n","plot_img_bbox(tensorToPIL(img), nms_preds)"],"metadata":{"id":"ftKNwKC8gmXs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_dataset = FruitImageDataset(test_dir, 480, 480, transforms= get_transform(train=True))\n","# pick one image from the test set\n","img, target = test_dataset[10]\n","# put the model in evaluation mode\n","fast_rcnn.eval()\n","with torch.no_grad():\n","    prediction = fast_rcnn([img.to(device)])[0]\n","\n","print('EXPECTED OUTPUT\\n')\n","plot_img_bbox(tensorToPIL(img), target)\n","print('MODEL OUTPUT\\n')\n","nms_prediction = apply_nms(prediction, threshold=0.01)\n","\n","plot_img_bbox(tensorToPIL(img), nms_prediction)"],"metadata":{"id":"CwGCciHPgtiR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fast_rcnn"],"metadata":{"id":"YadS6HYagxxn"},"execution_count":null,"outputs":[]}]}