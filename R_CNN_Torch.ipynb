{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1CWIHz1URWERbE4_bz1BRdsLbbHQI5N8k","timestamp":1676595675784}],"authorship_tag":"ABX9TyPJAMZWtNZ5EpyldoiK4grO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["jupyter-lab --allow-root --NotebookApp.allow_origin='https://colab.research.google.com' --port=8888 --NotebookApp.port_retries=0"],"metadata":{"id":"1vjHbyq9PhaV"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"sdCCRUUbyzYU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset\n","from torchvision.transforms import ToTensor\n","from PIL import Image\n","import os\n","import json\n","from torchvision.models.detection import fasterrcnn_resnet50_fpn\n","import torch.optim as optim\n","import torchvision.transforms.functional as TF\n","import torch.nn.functional as F"],"metadata":{"id":"JMmf2SCHy12Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CustomDataset(Dataset):\n","    def __init__(self, image_dir, label_dir, transform=None):\n","        self.image_dir = image_dir\n","        self.label_dir = label_dir\n","        self.transform = transform\n","        self.image_files = os.listdir(self.image_dir)\n","        self.label_files = os.listdir(self.label_dir)\n","\n","    def __len__(self):\n","        return len(self.image_files)\n","\n","    def __getitem__(self, idx):\n","        image_filename = self.image_files[idx]\n","        image_path = os.path.join(self.image_dir, image_filename)\n","        label_filename = image_filename.replace(\".tif\", \".json\")\n","        label_path = os.path.join(self.label_dir, label_filename)\n","\n","        # Load image\n","        image = Image.open(image_path)\n","\n","        # Read label file\n","        with open(label_path, 'r') as f:\n","            label_data = json.load(f)\n","\n","        # Extract bounding box coordinates\n","        boxes = []\n","        for obj in label_data[\"objects\"]:\n","            if obj[\"classTitle\"] == \"Oil tank\":  # Assuming the class name for oil tanks is \"Oil tank\"\n","                bbox = obj[\"points\"][\"exterior\"]\n","                x_min, y_min = bbox[0]\n","                x_max, y_max = bbox[1]\n","                boxes.append([x_min, y_min, x_max, y_max])\n","\n","        # Convert to tensors\n","        image_tensor = ToTensor()(image)\n","        boxes_tensor = torch.tensor(boxes, dtype=torch.float32)\n","\n","        # Labels are not used in Faster R-CNN, but we include them for consistency\n","        num_boxes = len(boxes)\n","        labels_tensor = torch.ones((num_boxes,), dtype=torch.int64)\n","\n","        target = {}\n","        target[\"boxes\"] = boxes_tensor\n","        target[\"labels\"] = labels_tensor\n","\n","        return image_tensor, target\n"],"metadata":{"id":"lreU9hFcy3rm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set the directory paths in your Google Drive\n","drive_path = \"/content/drive/MyDrive/oiltank_dataset\"\n","image_dir = os.path.join(drive_path, \"train_images\")\n","label_dir = os.path.join(drive_path, \"train_labels\")"],"metadata":{"id":"WDdS3knny5Zw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set the transformation\n","transform = None  # You can add additional transformations if needed"],"metadata":{"id":"REVgZMDszD-D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create the custom dataset\n","dataset = CustomDataset(image_dir, label_dir, transform=transform)"],"metadata":{"id":"-gAaFefPzFhA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set batch size and create data loader\n","batch_size = 16\n","dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)"],"metadata":{"id":"VeXUNqJBzHrk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train your Faster R-CNN model using the dataloader\n","model = fasterrcnn_resnet50_fpn(pretrained=True)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)\n"],"metadata":{"id":"-JTjKsMEzKIG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set the optimizer\n","optimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005)"],"metadata":{"id":"4css66vYzMXk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set the number of epochs\n","num_epochs = 10"],"metadata":{"id":"0TqM9gKnzMZp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def compute_loss(targets, outputs):\n","    # Extract the predicted labels and bounding boxes from the model outputs\n","    pred_labels = outputs[\"labels\"]\n","    pred_boxes = outputs[\"boxes\"]\n","\n","    # Extract the ground truth labels and bounding boxes from the targets\n","    gt_labels = targets[\"labels\"]\n","    gt_boxes = targets[\"boxes\"]\n","\n","    # Compute the classification loss\n","    classification_loss = F.cross_entropy(pred_labels, gt_labels)\n","\n","    # Compute the regression loss\n","    regression_loss = F.smooth_l1_loss(pred_boxes, gt_boxes)\n","\n","    # Combine the classification and regression losses\n","    loss = classification_loss + regression_loss\n","\n","    return loss"],"metadata":{"id":"BtdR_P8AzMbv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for epoch in range(num_epochs):\n","    for images, targets in dataloader:\n","        images = images.to(device)\n","        targets = {k: v.to(device) for k, v in targets.items()}\n","\n","        # Forward pass\n","        outputs = model(images, targets)\n","\n","        # Compute the loss\n","        loss = compute_loss(targets, outputs)\n","\n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Print the loss every few iterations\n","        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"],"metadata":{"id":"j17IDRwwzMeF"},"execution_count":null,"outputs":[]}]}